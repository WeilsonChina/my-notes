### 模型并行的需求

google的gnmt的训练过程是时使用了8块gpu卡, 将模型分布在不同的卡上进行的.

模型并行是很难用在在线服务的, 主要是成本的问题, gpu卡非常的贵. 

主要用在科研, 探索过程, 不断的探索到底任务可以达到什么程度. 作为模型的baseline, 然后可以进一步的开展工作
1. 模型压缩
2. 模型缩小



### tensorflow

tensorflow 本身是支持模型并行的.
