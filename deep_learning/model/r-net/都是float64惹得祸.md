去年年底的时候, 跟qa组有过一次交流.

新的question_answer作为一个服务, 需要一个模型来执行这个任务.

因为是要作为一个线上的任务. 所以对于延时是有要求的.

但是在P40上70ms的情况下, 实在是无法搞定上线的任务.

昨天在沟通其他问题的时候, 提到这个模型, 竟然降到了5ms,太不可思议了, 那就实验一把吧.

中间过程不表.

### 结论

tf.float64和tf.float32的执行效率, 有一个数量级的差别.


