### xla 的目的

#### 改进执行速度
1. 对于子图进行编译, 减少短时操作的执行时间, 消除 tensorflow 运行时先相关的开销
2. 融合pipeline操作, 减少内存开销
3. 针对已知的tensor的形状, 支持更加积极的常数传播

#### 减少内存的使用
1. 分析并调度内存使用, 原则上可以消除很多临时变量


#### 减少对于custom ops的依赖
1. 通过提高底层操作自动融合的性能, 让其和定制操作中的手工融合一样高效, 消除很多定制操作的必要性.

#### 减少mobile footprint


#### 改善可移植性
为新硬件编写新的后端会相对容易一些. 因为大部分 TF 程序不需要怎么修改就可以在新硬件上跑. 这和专门为新硬件定制一体化的操作形成对比.


### ref
1. https://tensorflow.juejin.im/performance/xla/index.html
