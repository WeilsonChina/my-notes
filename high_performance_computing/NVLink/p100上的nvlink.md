1. nvlink 的宣传是说带宽160GB/s.
2. p100 gpu上有4条 nvlink.
以前没有细想这个问题, 一直以为是每条nvlink都是160GB/s. 但是最近对TPU很感兴趣, 想搞明白到底TPUv2的网络互连是怎么做的. 

看了一个分析的文档, 讲 TPUv2有4条bluelink, 每条bluelink的带宽是25GB/s, 25GB/s vs 160GB/s这个差距也是太大了. 
让我产生了疑问, 就是虽然谷歌不是专业的硬件公司, 但是谷歌有足够的资本,花钱用最好的设计和生产方啊.
为什么不用更高的带宽, 低带宽对于模型训练可是一个瓶颈.

今天仔细的看了一下p100的slide文档, 原来是我搞错了, 不是每条nvlink 160GB/s, 而是4条的带宽总和是160GB/s.


这样看, nvlink和bluelink是一个level的解决方案.
